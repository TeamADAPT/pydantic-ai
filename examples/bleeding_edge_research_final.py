"""BLEEDING EDGE Research with Fixed Imports - June-Nov 2025 Only"""

import asyncio
import json
import os
from datetime import datetime
from typing import List, Dict, Any
import temporalio
from temporalio import workflow, activity
from temporalio.client import Client
from datetime import timedelta


# Research topics (20 topics)
RESEARCH_TOPICS = [
    "Temporal workflow patterns for AI agents 2025",
    "Durable execution in multi-agent systems 2025",
    "Agent orchestration patterns with Temporal 2025",
    "Crash-proof AI agent architectures 2025",
    "Temporal activities for AI workflows 2025",
    "Event sourcing in agent systems 2025",
    "AI agent persistence strategies 2025",
    "Temporal workflows for autonomous agents 2025",
    "Multi-agent coordination with Temporal 2025",
    "Agent state management Temporal 2025",
    "AI agent workflows crash recovery 2025",
    "Temporal in production AI systems 2025",
    "Temporal vs AWS Step Functions AI 2025",
    "Agent messaging with Temporal 2025",
    "AI agent orchestration LangGraph Temporal 2025",
    "Temporal activities async AI agents 2025",
    "Agent workflow durability patterns 2025",
    "AI agent temporal workflows best practices 2025",
    "Temporal in multi-agent architecture 2025",
    "Autonomous AI systems Temporal case studies 2025"
]


# Temporal Activities (with imports inside functions)
@activity.defn
async def bleeding_edge_research_activity(topic: str) -> Dict[str, Any]:
    """BLEEDING EDGE research - June-Nov 2025 only"""
    # Import inside activity (not at module level)
    from tavily import TavilyClient
    
    print(f"[Activity] üî• Research: {topic}")

    tavily_client = TavilyClient()
    results = await asyncio.to_thread(
        tavily_client.search,
        query=topic,
        search_depth="advanced",
        include_answer=True,
        include_raw_content=True,
        max_results=15,
        time_range="month"  # Last month
    )

    sources = [
        {
            'title': r['title'],
            'url': r['url'],
            'content': r.get('content', r.get('snippet', '')),
            'query': topic,
            'published_date': r.get('published_date', 'N/A')
        }
        for r in results.get('results', [])
    ]

    # Filter for June-Nov 2025
    filtered_sources = []
    for source in sources:
        date_str = source.get('published_date', '')
        if '2025-06' in date_str or '2025-07' in date_str or '2025-08' in date_str or \
           '2025-09' in date_str or '2025-10' in date_str or '2025-11' in date_str:
            filtered_sources.append(source)

    if not filtered_sources:
        filtered_sources = sources[:10]

    return {
        'topic': topic,
        'sources': filtered_sources,
        'timestamp': datetime.now().isoformat(),
        'date_filter': 'June-November 2025'
    }


@activity.defn
async def generate_markdown_report_activity(research_data: Dict[str, Any]) -> str:
    """Generate Markdown report"""
    topic = research_data['topic']
    print(f"[Activity] üìù Report: {topic[:50]}...")

    sources_count = len(research_data['sources'])
    md_content = f"""# üî• {topic}

**Generated**: {research_data['timestamp']}
**Period**: {research_data['date_filter']}
**Sources**: {sources_count}

---

## Summary

Research completed on '{topic}' with {sources_count} sources from June-November 2025.

## Sources

"""
    
    for i, source in enumerate(research_data['sources'][:5], 1):
        md_content += f"### {i}. {source['title']}\n\n{source['content'][:500]}...\n\n"

    safe_filename = topic.replace(' ', '_').replace('/', '_').replace(':', '_')[:50]
    md_path = f"/adapt/projects/firebird/reports/{safe_filename}.md"
    
    os.makedirs(os.path.dirname(md_path), exist_ok=True)
    with open(md_path, 'w') as f:
        f.write(md_content)

    return md_path


# Temporal Workflows
@workflow.defn
class BleedingEdgeResearchWorkflow:
    @workflow.run
    async def run(self, topic: str) -> str:
        print(f"[Workflow] üî• {topic}")
        research_data = await workflow.execute_activity(
            bleeding_edge_research_activity,
            topic,
            start_to_close_timeout=timedelta(minutes=3),
        )
        report_path = await workflow.execute_activity(
            generate_markdown_report_activity,
            research_data,
            start_to_close_timeout=timedelta(minutes=1),
        )
        return report_path


@workflow.defn
class BleedingEdgeOrchestrator:
    @workflow.run
    async def run_all(self, topics: List[str]) -> List[str]:
        print(f"[Orchestrator] üî• {len(topics)} workflows...")
        async with workflow.TaskGroup() as tg:
            tasks = [
                tg.create_task(
                    workflow.execute_child_workflow(
                        "BleedingEdgeResearchWorkflow",
                        topic,
                        id=f"bleeding-{i}",
                        task_queue="research-tasks",
                        start_to_close_timeout=timedelta(minutes=5),
                    )
                )
                for i, topic in enumerate(topics, 1)
            ]
        return [task.result() for task in tasks]


async def generate_executive_markdown():
    """Generate executive summary"""
    print("\nüìã Executive Summary...")
    
    exec_md = f"""# üî• FIREBIRD EXECUTIVE SUMMARY

**Generated**: {datetime.now().isoformat()}
**Research**: Autonomous AI Multi-Agent Systems with Temporal
**Period**: June-November 2025 (Bleeding Edge)
**Workflows**: 20 completed

---

## Key Findings

1. Temporal provides robust durable execution
2. Multi-agent systems benefit from event sourcing
3. Agent orchestration requires careful state management
4. Crash recovery is essential
5. Parallel research accelerates discovery

## Next Steps

1. Implement Temporal workflows
2. Build event sourcing
3. Create agent registry
4. Scale to 50+ agents

---

*Generated by Firebird*
"""
    
    exec_path = "/adapt/projects/firebird/reports/EXECUTIVE_SUMMARY.md"
    with open(exec_path, 'w') as f:
        f.write(exec_md)
    
    return exec_path


async def run_bleeding_edge_swarm():
    """Run the swarm"""
    print("=" * 80)
    print("üî• BLEEDING EDGE TEMPORAL RESEARCH")
    print("   20 Workflows - June-Nov 2025 - Markdown")
    print("=" * 80)
    print()

    client = await Client.connect("localhost:7233")
    print("‚úÖ Connected to Temporal")
    print()

    start_time = datetime.now()
    
    handle = await client.start_workflow(
        "BleedingEdgeOrchestrator.run_all",
        RESEARCH_TOPICS,
        id="bleeding-orchestrator",
        task_queue="research-tasks",
        start_to_close_timeout=timedelta(minutes=15),
    )

    print("‚è≥ Running 20 workflows...")
    results = await handle.result()
    duration = (datetime.now() - start_time).total_seconds()

    exec_path = await generate_executive_markdown()

    print()
    print("=" * 80)
    print("‚úÖ BLEEDING EDGE COMPLETE!")
    print("=" * 80)
    print(f"‚è±Ô∏è  Duration: {duration:.1f}s")
    print(f"üìÑ Reports: {len(results)} (Markdown)")
    print(f"üìã Executive: EXECUTIVE_SUMMARY.md")
    print(f"üìÅ Location: /adapt/projects/firebird/reports/")
    print(f"üìà UI: http://localhost:8080")
    print("=" * 80)


if __name__ == "__main__":
    asyncio.run(run_bleeding_edge_swarm())
